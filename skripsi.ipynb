{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter transfer learning\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output # untuk mendapatkan output dari model VGG16\n",
    "x = GlobalAveragePooling2D()(x) # mengubah fitur dari layer konvolusional menjadi vektor tunggal\n",
    "x = Dense(1024, activation='relu')(x) # mempelajari pola-pola kompleks dari fitur-fitur yang diekstraksi oleh layer konvolusional\n",
    "predictions = Dense(4, activation='softmax')(x) # untuk menghasilkan probabilitas untu setiap kelas\n",
    "model = Model(inputs=base_model.input, outputs=predictions) # mendefinisikan input dari model VGG16 dan output dari prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#untuk menjaga bobot dari model dasar tetap stabil dan fokus melatih bagian yang baru saja\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Direktori asal gambar dan direktori tujuan train dan validation\n",
    "original_dataset_dir = 'E:\\\\SKRIPSI_MIRZA\\\\batik'\n",
    "base_dir = 'E:\\\\SKRIPSI_MIRZA\\\\data'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(validation_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "for class_name in ['kawung', 'megamendung','parang','random']:  # nama kelas\n",
    "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(validation_dir, class_name), exist_ok=True)\n",
    "\n",
    "    files = os.listdir(os.path.join(original_dataset_dir, class_name))\n",
    "    random.shuffle(files)\n",
    "    \n",
    "    train_split = int(0.7 * len(files))\n",
    "    validation_split = int(0.9 * len(files))\n",
    "\n",
    "    train_files = files[:train_split]\n",
    "    validation_files = files[train_split:validation_split]\n",
    "    test_files = files[validation_split:]\n",
    "    \n",
    "    for file in train_files:\n",
    "        shutil.copy(os.path.join(original_dataset_dir, class_name, file),\n",
    "                    os.path.join(train_dir, class_name, file))\n",
    "    \n",
    "    for file in validation_files:\n",
    "        shutil.copy(os.path.join(original_dataset_dir, class_name, file),\n",
    "                    os.path.join(validation_dir, class_name, file))\n",
    "\n",
    "    for file in test_files:\n",
    "        shutil.copy(os.path.join(original_dataset_dir, class_name, file),\n",
    "                    os.path.join(test_dir, class_name, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 194 images belonging to 4 classes.\n",
      "Found 103 images belonging to 4 classes.\n",
      "Found 64 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - accuracy: 0.3019 - loss: 1.4492 - val_accuracy: 0.6667 - val_loss: 0.8765\n",
      "Epoch 2/10\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.6250 - loss: 1.0277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BAYU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.6250 - loss: 1.0277 - val_accuracy: 0.8571 - val_loss: 0.7809\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6868 - loss: 0.8298 - val_accuracy: 0.7604 - val_loss: 0.6195\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.8125 - loss: 0.6075 - val_accuracy: 0.8571 - val_loss: 0.6551\n",
      "Epoch 5/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - accuracy: 0.8067 - loss: 0.5683 - val_accuracy: 0.8229 - val_loss: 0.5037\n",
      "Epoch 6/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.8750 - loss: 0.3915 - val_accuracy: 1.0000 - val_loss: 0.3032\n",
      "Epoch 7/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.8099 - loss: 0.4884 - val_accuracy: 0.8646 - val_loss: 0.3567\n",
      "Epoch 8/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.8125 - loss: 0.4239 - val_accuracy: 1.0000 - val_loss: 0.1820\n",
      "Epoch 9/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.8648 - loss: 0.3754 - val_accuracy: 0.8542 - val_loss: 0.3882\n",
      "Epoch 10/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.8125 - loss: 0.5053 - val_accuracy: 1.0000 - val_loss: 0.1484\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // validation_generator.batch_size,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[15:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "Predicted Class: random\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Nama kelas yang ada dalam model Anda\n",
    "class_names = ['kawung', 'megamendung', 'parang','random']\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Muat dan preprocess gambar\n",
    "    img = image.load_img(image_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0  # Normalisasi\n",
    "    return img_array\n",
    "\n",
    "def predict_image(image_path, model, threshold=0.8):\n",
    "    img_array = preprocess_image(image_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    max_prob = np.max(predictions)\n",
    "    predicted_class = np.argmax(predictions)\n",
    "\n",
    "    if max_prob < threshold:\n",
    "        return 'random'\n",
    "    elif predicted_class == 0:\n",
    "        return 0  # Kawung\n",
    "    elif predicted_class == 1:\n",
    "        return 1  # Megamendung\n",
    "    elif predicted_class == 2:\n",
    "        return 2  # Parang\n",
    "    else:\n",
    "        return'random'\n",
    "\n",
    "# Contoh penggunaan\n",
    "image_path = 'E:\\\\latihan\\\\my_flask_app\\\\static\\\\css\\\\images\\\\12.jpg'  # Ganti dengan path gambar sembarang Anda\n",
    "result = predict_image(image_path, model, threshold=0.8)\n",
    "print(f'Predicted Class: {result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('agus_babik.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
